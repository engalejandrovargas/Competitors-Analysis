{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "836b2118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da85f370",
   "metadata": {},
   "source": [
    "# Explanation\n",
    "\n",
    "The custom score is a metric that I've created to rank the keywords based on their potential value for our SEO campaign. It's designed to balance three key factors: search volume, SEO difficulty, and estimated visits. Here's how it works:\n",
    "\n",
    "Search Volume (Volume): This represents the number of times a keyword is searched for in a given period. Higher search volume means more potential traffic.\n",
    "\n",
    "SEO Difficulty (Seo Difficulty): This indicates how difficult it is to rank for a keyword. A lower SEO difficulty means it's easier to rank for the keyword.\n",
    "\n",
    "Estimated Visits (Est. Visits): This is an estimate of the number of visits your website could receive if it ranks well for the keyword. Higher estimated visits mean more potential traffic.\n",
    "\n",
    "The custom score combines these factors using the formula:\n",
    "\n",
    "`Score = (Normalized Volume + Normalized Est. Visits) - Normalized Seo Difficulty`\n",
    "\n",
    "Here's what each part of the formula means:\n",
    "\n",
    "Normalized Volume: The search volume is normalized to a scale of 0 to 1. This ensures that it's comparable with the other metrics.\n",
    "\n",
    "Normalized Est. Visits: The estimated visits are also normalized to a scale of 0 to 1.\n",
    "\n",
    "Normalized Seo Difficulty: The SEO difficulty is normalized to a scale of 0 to 1. However, since we want a lower SEO difficulty to be better, we subtract this value from the sum of the normalized volume and estimated visits.\n",
    "\n",
    "By combining these normalized values, the score provides a balanced measure of a keyword's potential value. Keywords with higher scores are considered better for our SEO campaign because they have a good combination of high search volume, high estimated visits, and low SEO difficulty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a835ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import datetime\n",
    "\n",
    "def get_top_20_keywords(file_path):\n",
    "    # Read the data\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    df = df.drop(columns=['No', 'Position', 'Ranking Url'])\n",
    "\n",
    "    # Normalize the columns\n",
    "    scaler = MinMaxScaler()\n",
    "    df[['Volume', 'Seo Difficulty', 'Est. Visits']] = scaler.fit_transform(df[['Volume', 'Seo Difficulty', 'Est. Visits']])\n",
    "\n",
    "    # Create a custom score\n",
    "    df['Score'] = (df['Volume'] + df['Est. Visits']) - df['Seo Difficulty']\n",
    "\n",
    "    # Sort the DataFrame by the custom score in descending order\n",
    "    df_sorted = df.sort_values(by='Score', ascending=False)\n",
    "\n",
    "    # Get the top 20 keywords\n",
    "    top_20_keywords = df_sorted.head(20)\n",
    "\n",
    "    return top_20_keywords\n",
    "\n",
    "def save_top_keywords_to_excel(directory):\n",
    "    # Get today's date in YYYY-MM-DD format\n",
    "    today = datetime.date.today().strftime('%Y-%m-%d')\n",
    "\n",
    "    # Define the output file name with today's date\n",
    "    output_file = f'top_keywords_{today}.xlsx'\n",
    "\n",
    "    # Get the paths of all CSV files in the directory\n",
    "    file_paths = glob.glob(f'{directory}/*.csv')\n",
    "\n",
    "    # Process each file and concatenate the results\n",
    "    all_top_keywords = pd.concat([get_top_20_keywords(file_path) for file_path in file_paths])\n",
    "\n",
    "    # Reset the index\n",
    "    all_top_keywords.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Save the concatenated top keywords to an Excel file\n",
    "    all_top_keywords.to_excel(output_file, index=False)\n",
    "\n",
    "    # Return the name of the output file\n",
    "    return output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "453e9beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top keywords saved to top_keywords_2024-02-25.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "directory = 'Data/'\n",
    "output_file = save_top_keywords_to_excel(directory)\n",
    "print(f'Top keywords saved to {output_file}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9456b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
